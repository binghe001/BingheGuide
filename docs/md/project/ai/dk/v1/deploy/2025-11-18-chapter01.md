---
title: 第01节：DeepSeek本地部署+知识库+联网搜索
pay: https://articles.zsxq.com/id_borqbwv1nupn.html
---

# 《实战AI大模型》部署大模型-第01节：DeepSeek本地部署+知识库+联网搜索

作者：冰河
<br/>星球：[http://m6z.cn/6aeFbs](http://m6z.cn/6aeFbs)
<br/>博客：[https://binghe.gitcode.host](https://binghe.gitcode.host)
<br/>文章汇总：[https://binghe.gitcode.host/md/all/all.html](https://binghe.gitcode.host/md/all/all.html)
<br/>源码获取地址：[https://t.zsxq.com/0dhvFs5oR](https://t.zsxq.com/0dhvFs5oR)

**大家好，我是冰河~~**

本地安装DeepSeek不仅仅对电脑的配置有一定的要求，而且大部分场景下，在本地安装的DeepSeek不能联网搜索。这一系列的问题，让不少小伙伴不得不放弃本地部署DeepSeek大模型的想法。今天冰河就带着大家，实现一个本地部署+私人知识库+联网搜索的终极方案。

## 一、本地部署DeepSeek

首先打开ollama官网：[https://ollama.com](https://ollama.com)

<div align="center">
    <img src="https://binghe.gitcode.host/images/project/ai/2026-11-18-001.png?raw=true" width="70%">
    <br/>
</div>

下载，一步步安装即可。

CMD命令窗口运行，启动deepseek-r1模型：

````bash
ollama run deepseek-r1:7b
````

<div align="center">
    <img src="https://binghe.gitcode.host/images/project/ai/2026-11-18-002.png?raw=true" width="70%">
    <br/>
</div>

根据自己显卡大小，选择对应的参数规模，1.5b最小，可以先用这个来尝试，完成以后再跑更大的参数模型。

另外有人反馈，任务管理器显示，大模型在执行的时候，回答很慢，GPU几乎没动，全都是CPU在跑。

大概率是安装了老版本的Ollama，官网下载最新的文件重新安装即可。

## 二、安装Page Assist插件

网络条件允许的话，直接谷歌商店搜索下载，下面介绍的方法国内网络可用。

打开网站Crx搜搜：[https://www.crxsoso.com](https://www.crxsoso.com)

搜索：Page Assist，第一个就是今天主角，本地AI模型的Web UI。

<div align="center">
    <img src="https://binghe.gitcode.host/images/project/ai/2026-11-18-003.png?raw=true" width="70%">
    <br/>
</div>

下载到本地，谷歌浏览器打开：chrome://extensions/，右上角打开开发者模式，将下载好的crx文件拖入浏览器，完成插件的安装。

<div align="center">
    <img src="https://binghe.gitcode.host/images/project/ai/2026-11-18-004.png?raw=true" width="70%">
    <br/>
</div>

浏览器上方的扩展程序列表，找到Page Assist插件，点击进入WebUI界面。

## 查看完整文章

加入[冰河技术](https://public.zsxq.com/groups/48848484411888.html)知识星球，解锁完整技术文章、小册、视频与完整代码