---
title: 第01节：构建生成式AI应用-安装Ollama+Dify
pay: https://articles.zsxq.com/id_e0epvzmgwuvh.html
---

# 《实战AI大模型》生成AI应用-第01节：构建生成式AI应用-安装Ollama+Dify

作者：冰河
<br/>星球：[http://m6z.cn/6aeFbs](http://m6z.cn/6aeFbs)
<br/>博客：[https://binghe.gitcode.host](https://binghe.gitcode.host)
<br/>文章汇总：[https://binghe.gitcode.host/md/all/all.html](https://binghe.gitcode.host/md/all/all.html)
<br/>源码获取地址：[https://t.zsxq.com/0dhvFs5oR](https://t.zsxq.com/0dhvFs5oR)

**大家好，我是冰河~~**

从今天开始，我们正式开始实战AI大模型专栏新的篇章，那就是生成AI应用。也就是说，在接下来的几天时间内，我们在实战AI大模型专栏中，重心开始从部署大模型转变到生成AI应用。

## 一、Dify概要

Dify作为一款开源的大语言模型应用开发平台，通过低代码和无代码的设计理念，显著降低了构建生成式AI应用的技术门槛。

**（1）可视化低代码开发体验**
Dify提供直观的图形化界面，支持通过拖拽组件和配置参数的方式快速构建AI应用逻辑。无论是提示词工程、上下文管理还是复杂的工作流编排，都无需编写大量代码，使得非技术背景的团队成员也能参与应用开发。

**（2）多模型支持与灵活集成**
平台深度集成主流大语言模型，包括OpenAI GPT系列、Claude、Llama3等，同时支持自定义模型接入。开发者可以根据具体场景需求灵活切换模型，结合RAG检索增强生成技术，有效提升生成内容的准确性和专业性。

**（3）企业级特性与安全部署**
支持完整的私有化部署方案，确保敏感数据不会外泄，满足金融、政务等对数据安全要求严格的场景需求。平台内置完善的监控告警、日志分析和权限管理体系，完全符合企业生产环境标准。

**（4）丰富的应用场景支持**
覆盖智能客服、内容创作、数据分析、知识库问答等多种业务场景。特别是通过RAG技术，能够高效解析PDF、PPT、Word等文档格式，构建专业领域的知识库系统。

**（5）开源生态与商业友好**
基于Apache 2.0开源协议，允许商业使用。社区版本提供完整的基础功能，企业版则提供多租户管理等高级特性，形成良好的开源商业模式。

## 二、准备安装环境

### 2.1 Dify环境要求

在开始安装之前，需确保目标环境满足以下最低配置要求：

- CPU核心数 >= 2核
- 内存容量 >= 4GB
- 存储空间 >= 20GB（根据模型大小调整）

操作系统要求：

- Docker 19.03 或更高版本
- Docker Compose 1.28 或更高版本
- 已安装Ollama本地模型服务

### 2.2 准备CloudStudio环境 

CloudStudio链接：[https://ide.cloud.tencent.com/dashboard/gpu-workspace](https://ide.cloud.tencent.com/dashboard/gpu-workspace)

<div align="center">
    <img src="https://binghe.gitcode.host/images/project/ai/2026-12-02-001.png?raw=true" width="70%">
    <br/>
</div>

选择DeepSeek-R1 32B配置后，系统开始准备研发环境：

<div align="center">
    <img src="https://binghe.gitcode.host/images/project/ai/2026-12-02-002.png?raw=true" width="70%">
    <br/>
</div>

 环境准备完成后，进入主工作界面：

## 查看完整文章

加入[冰河技术](https://public.zsxq.com/groups/48848484411888.html)知识星球，解锁完整技术文章、小册、视频与完整代码