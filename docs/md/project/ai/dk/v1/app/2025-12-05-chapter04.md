---
title: 第04节：通过Ollama+Dify+Qwen3创建Agent应用
pay: https://articles.zsxq.com/id_m89wd4mlswcq.html
---

# 《实战AI大模型》生成AI应用-第04节：通过Ollama+Dify+Qwen3创建Agent应用

作者：冰河
<br/>星球：[http://m6z.cn/6aeFbs](http://m6z.cn/6aeFbs)
<br/>博客：[https://binghe.gitcode.host](https://binghe.gitcode.host)
<br/>文章汇总：[https://binghe.gitcode.host/md/all/all.html](https://binghe.gitcode.host/md/all/all.html)
<br/>源码获取地址：[https://t.zsxq.com/0dhvFs5oR](https://t.zsxq.com/0dhvFs5oR)

**大家好，我是冰河~~**

在前面的实践中，我们基于Ollama+Dify+DeepSeek+searxng成功构建了Agent应用。今天，我们继续基于新一代开源模型Qwen3，打造更强大的智能旅行规划助手。Qwen3作为阿里巴巴开源的最新模型，在多个基准测试中表现出色，尤其在工具调用和智能体能力方面具有显著优势。

## 一、Qwen3模型的核心优势

2025年4月，阿里巴巴开源了新一代通义千问模型Qwen3系列。其中旗舰模型Qwen3-235B-A22B在代码、数学、通用能力等测试中，与DeepSeek-R1、Gemini-2.5-Pro等顶级模型相比展现出强大的竞争力。更令人印象深刻的是，小型MoE模型Qwen3-30B-A3B仅激活10%的参数就能超越QwQ-32B的性能。

关键技术特性：

**双模式推理能力**：

- **思考模式**：适用于复杂逻辑推理、数学计算和编程任务，模型会进行逐步推理后给出答案
- **非思考模式**：针对简单问题提供快速响应，优化对话效率

这种双模式设计让用户能够根据任务复杂度灵活控制模型的“思考深度”，在性能与效率之间实现最优平衡。

**卓越的工具调用能力**：

Qwen3原生支持MCP协议，具备强大的函数调用（function calling）能力。配合Qwen-Agent框架的工具调用模板和解析器，大大降低了编码复杂度，为实现高效的设备操作Agent提供了坚实基础。

**全面的模型尺寸覆盖**：

提供从0.6B到235B的全尺寸稠密与混合专家模型，满足不同场景下的部署需求。

## 一、云端开发环境准备

我们继续使用腾讯Cloud Studio作为开发环境，这个云端IDE提供了开箱即用的GPU计算资源：

<div align="center">
    <img src="https://binghe.gitcode.host/images/project/ai/2026-12-05-001.png?raw=true" width="70%">
    <br/>
</div>

访问[Cloud Studio](https://ide.cloud.tencent.com/)并完成注册登录后，进入工作空间管理界面。如果预置的Ollama环境不可用，可以选择PyTorch等基础环境手动安装所需组件：

<div align="center">
    <img src="https://binghe.gitcode.host/images/project/ai/2026-12-05-002.png?raw=true" width="70%">
    <br/>
</div>

选择适合的资源配置开始创建环境，这个过程通常需要几分钟时间

## 查看完整文章

加入[冰河技术](https://public.zsxq.com/groups/48848484411888.html)知识星球，解锁完整技术文章、小册、视频与完整代码