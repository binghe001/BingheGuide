---
title: 第108章：秒杀系统整合日志治理
pay: https://articles.zsxq.com/id_2s53oznk3aox.html
---

# 《Seckill秒杀系统》第108章：秒杀系统整合日志治理

作者：冰河
<br/>星球：[http://m6z.cn/6aeFbs](http://m6z.cn/6aeFbs)
<br/>博客：[https://binghe.gitcode.host](https://binghe.gitcode.host)
<br/>文章汇总：[https://binghe.gitcode.host/md/all/all.html](https://binghe.gitcode.host/md/all/all.html)
<br/>源码获取地址：[https://t.zsxq.com/0dhvFs5oR](https://t.zsxq.com/0dhvFs5oR)

> 沉淀，成长，突破，帮助他人，成就自我。

* 本章难度：★★☆☆☆
* 本章重点：秒杀系统整合日志治理，实现可视化日志排查与搜索功能，实现可视化日志监控功能，掌握日志治理在业务系统中的落地实现方案，并能够将日志治理的方案和实现方式灵活应用到自身实际项目中。

**大家好，我是冰河~~**

日志治理是秒杀系统建设过程中非常重要的一环，通过可视化的日志治理方案，能够直观、方便的查看日志，监控系统的执行流程，并对系统的运行情况进行监控，及时发现问题和性能瓶颈，快速处理。

## 一、前言

在前面的文章中，我们系统的讲述了日志治理的基本知识、原则与架构，并且快速搭建了ELK环境。接下来，就需要在秒杀系统中整合日志治理，通过ELK可视化的方式对系统的日志进行观测和监控，以便及时发现秒杀系统的问题和性能瓶颈，进而进一步进行处理。

## 二、本章诉求

秒杀系统整合ELK实现日志治理，最终实现日志观测和监控的可视化，及时发现秒杀系统的问题和性能瓶颈，进而进一步处理相关的问题和提升秒杀系统的性能，最终能够将日志治理的方案和实现方式灵活应用到自身实际项目中。

## 三、秒杀系统整合ELK

秒杀系统整合ELK实现日志治理就比较简单了，具体整合步骤如下所示。

**（1）引入logback依赖**

在秒杀系统的pom.xml文件中引入logback依赖，如下所示。

```xml
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>${logstash-logback.version}</version>
</dependency>
```

**（2）配置logback-spring.xml文件**

在每个微服务的启动工程下的`src/main/resources`目录下新增logback-spring.xml文件，以用户微服务为例，logback-spring.xml文件的内容如下所示。

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>

    <property name="APP_NAME" value="seckill-user"/>
    <property name="LOG_PATH" value="${user.home}/${APP_NAME}/logs"/>
    <property name="LOG_FILE" value="${LOG_PATH}/application.log"/>

    <appender name="APPLICATION"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_FILE}</file>
        <encoder>
            <pattern>${FILE_LOG_PATTERN}</pattern>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${LOG_FILE}.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <maxHistory>7</maxHistory>
            <maxFileSize>50MB</maxFileSize>
            <totalSizeCap>20GB</totalSizeCap>
        </rollingPolicy>
    </appender>
    <conversionRule conversionWord="ip" converterClass="io.binghe.seckill.common.utils.ip.IPConverterConfig" />

    <appender name="LOG_STASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>192.168.184.102:5044</destination>
        <queueSize>1048576</queueSize>
        <encoder charset="UTF-8" class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
            <providers>
                <timestamp>
                    <timeZone>UTC</timeZone>
                </timestamp>
                <pattern>
                    <pattern>
                        {
                        "app_date": "%d{yyyy-MM-dd HH:mm:ss:SSS}",
                        "app_ip": "%ip",
                        "app_thread": "%thread",
                        "app_traceId": "%X{traceId}",
                        "app_level": "%level",
                        "app_logger": "%logger{40}",
                        "app_message": "%msg%n"
                        }
                    </pattern>
                </pattern>
            </providers>

        </encoder>
    </appender>

    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <charset>utf8</charset>
            <pattern>%d{yyyy-MM-dd HH:mm:ss:SSS}|%ip|%thread|%X{traceId}|%level|%logger{36}|%msg%n</pattern>
        </encoder>
    </appender>

    <root level="INFO">
        <appender-ref ref="LOG_STASH"/>
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="APPLICATION"/>
    </root>
</configuration>
```

可以看到，在用户微服务的logback-spring.xml文件中，配置了Logstash服务的地址，并且配置了JSON格式的结构化日志。通过指定Appender类型的日志，直接通过TCP的方式将日志发送给Logstash，并且将日志的格式设置为JSON格式。

另外，需要注意的是在用户微服务的logback-spring.xml文件中，有如下一行配置。

## 查看完整文章

加入[冰河技术](http://m6z.cn/6aeFbs)知识星球，解锁完整技术文章与完整代码